{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "# Use path length in wordnet to find word similarity\n",
    "# find sense of words via synonym set\n",
    "# n=noun, 01=synonym set for first meaning of the word\n",
    "deer = wn.synset('deer.n.01')\n",
    "deer\n",
    "\n",
    "elk = wn.synset('elk.n.01')\n",
    "deer.path_similarity(elk)\n",
    "\n",
    "horse = wn.synset('horse.n.01')\n",
    "deer.path_similarity(horse)\n",
    "\n",
    "# Use an information criteria to find word similarity\n",
    "from nltk.corpus import wordnet_ic\n",
    "brown_ic = wordnet_ic.ic('ic-brown.dat')\n",
    "deer.lin_similarity(elk, brown_ic)\n",
    "\n",
    "deer.lin_similarity(horse, brown_ic)\n",
    "\n",
    "# Use NLTK Collocation and Association Measures\n",
    "from nltk.collocations import *\n",
    "# load some text for examples\n",
    "from nltk.book import *\n",
    "# text1 is the book \"Moby Dick\"\n",
    "# extract just the words without numbers and sentence marks and make them lower case\n",
    "text = [w.lower() for w in list(text1) if w.isalpha()]\n",
    "\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "finder = BigramCollocationFinder.from_words(text)\n",
    "finder.nbest(bigram_measures.pmi,10)\n",
    "\n",
    "# find all the bigrams with occurrence of at least 10, this modifies our \"finder\" object\n",
    "finder.apply_freq_filter(10)\n",
    "finder.nbest(bigram_measures.pmi,10)\n",
    "\n",
    "# Working with Latent Dirichlet Allocation (LDA) in Python\n",
    "# Several packages available, such as gensim and lda. Text needs to be\n",
    "# preprocessed: tokenizing, normalizing such as lower-casing, stopword\n",
    "# removal, stemming, and then transforming into a (sparse) matrix for\n",
    "# word (bigram, etc) occurences.\n",
    "# generate a set of preprocessed documents\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.book import *\n",
    "\n",
    "len(stopwords.words('english'))\n",
    "\n",
    "stopwords.words('english')\n",
    "\n",
    "# extract just the stemmed words without numbers and sentence marks and make them lower case\n",
    "p_stemmer = PorterStemmer()\n",
    "sw = stopwords.words('english')\n",
    "doc1 = [p_stemmer.stem(w.lower()) for w in list(text1) if w.isalpha() and not w.lower() in sw]\n",
    "doc2 = [p_stemmer.stem(w.lower()) for w in list(text2) if w.isalpha() and not w.lower() in sw]\n",
    "doc3 = [p_stemmer.stem(w.lower()) for w in list(text3) if w.isalpha() and not w.lower() in sw]\n",
    "doc4 = [p_stemmer.stem(w.lower()) for w in list(text4) if w.isalpha() and not w.lower() in sw]\n",
    "doc5 = [p_stemmer.stem(w.lower()) for w in list(text5) if w.isalpha() and not w.lower() in sw]\n",
    "doc_set = [doc1, doc2, doc3, doc4, doc5]\n",
    "\n",
    "# under Windows this generates a warning\n",
    "import gensim\n",
    "from gensim import corpora, models\n",
    "\n",
    "dictionary = corpora.Dictionary(doc_set)\n",
    "dictionary\n",
    "\n",
    "# transform each document into a bag of words\n",
    "corpus = [dictionary.doc2bow((doc)) for doc in doc_set]\n",
    "\n",
    "# The corpus contains the 5 documents\n",
    "# each document is a list of indexed features and occurrence count (freq)\n",
    "print(type(corpus))\n",
    "print(type(corpus[0]))\n",
    "print(type(corpus[0][0]))\n",
    "print(corpus[0][::2000])\n",
    "\n",
    "# let's try 4 topics for our 5 documents\n",
    "# 50 passes takes quite a while, let's try less\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics=4, id2word=dictionary, passes=10)\n",
    "\n",
    "print(ldamodel.print_topics(num_topics=4, num_words=10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
